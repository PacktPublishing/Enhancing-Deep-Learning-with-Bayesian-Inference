{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install imagecorruptions\n",
        "!pip install imgaug"
      ],
      "metadata": {
        "id": "qFR87567AdMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade imgaug"
      ],
      "metadata": {
        "id": "seigaQeUBshi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Walk through the code example, using a vanilla neural network, A network trained with Bayes By Backprop and a deep ensemble.\n",
        "Use Cifar 10 data set and plot accuracy and calibration histograms over severity levels."
      ],
      "metadata": {
        "id": "mfpy9RWl5Nkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug.augmenters.imgcorruptlike as icl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "GPllJCh-u5i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare dataset"
      ],
      "metadata": {
        "id": "pOzqKz8VQXWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar = tf.keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()"
      ],
      "metadata": {
        "id": "hQeQN5_S_ykm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES = [\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        "]"
      ],
      "metadata": {
        "id": "UJAxqam5GtAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TRAIN_EXAMPLES = train_images.shape[0]"
      ],
      "metadata": {
        "id": "cuGZ_dG0QwJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define helper functions to define vanilla and ensemble networks"
      ],
      "metadata": {
        "id": "YcYKRDJfQbqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_building_block(num_filters):\n",
        "    return tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=num_filters, kernel_size=(3, 3), activation=\"relu\"\n",
        "            ),\n",
        "            tf.keras.layers.MaxPool2D(strides=2),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "def build_and_compile_model():\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Rescaling(1.0 / 255, input_shape=(32, 32, 3)),\n",
        "            cnn_building_block(16),\n",
        "            cnn_building_block(32),\n",
        "            cnn_building_block(64),\n",
        "            tf.keras.layers.MaxPool2D(strides=2),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "kFgbgMPlAko6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vanilla models"
      ],
      "metadata": {
        "id": "QM2h951cQe97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla_model = build_and_compile_model()\n",
        "vanilla_model.fit(train_images, train_labels, epochs=10)"
      ],
      "metadata": {
        "id": "pwu7d9aBBK6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep ensemble model"
      ],
      "metadata": {
        "id": "zLtiGfWWQoE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ENSEMBLE_MEMBERS = 5\n",
        "ensemble_model = []\n",
        "for ind in range(NUM_ENSEMBLE_MEMBERS):\n",
        "    member = build_and_compile_model()\n",
        "    print(f\"Train model {ind:02}\")\n",
        "    member.fit(train_images, train_labels, epochs=10)\n",
        "    ensemble_model.append(member)"
      ],
      "metadata": {
        "id": "M0LmARTBLsGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define helper functions to BBB network"
      ],
      "metadata": {
        "id": "jrS4KhaPQtlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_building_block_bbb(num_filters, kl_divergence_function):\n",
        "    return tf.keras.Sequential(\n",
        "        [\n",
        "            tfp.layers.Convolution2DReparameterization(\n",
        "                num_filters,\n",
        "                kernel_size=(3, 3),\n",
        "                kernel_divergence_fn=kl_divergence_function,\n",
        "                activation=tf.nn.relu,\n",
        "            ),\n",
        "            tf.keras.layers.MaxPool2D(strides=2),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "def build_and_compile_model_bbb():\n",
        "\n",
        "    kl_divergence_function = lambda q, p, _: tfp.distributions.kl_divergence(\n",
        "        q, p\n",
        "    ) / tf.cast(NUM_TRAIN_EXAMPLES, dtype=tf.float32)\n",
        "\n",
        "    model = tf.keras.models.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Rescaling(1.0 / 255, input_shape=(32, 32, 3)),\n",
        "            cnn_building_block_bbb(16, kl_divergence_function),\n",
        "            cnn_building_block_bbb(32, kl_divergence_function),\n",
        "            cnn_building_block_bbb(64, kl_divergence_function),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tfp.layers.DenseReparameterization(\n",
        "                64,\n",
        "                kernel_divergence_fn=kl_divergence_function,\n",
        "                activation=tf.nn.relu,\n",
        "            ),\n",
        "            tfp.layers.DenseReparameterization(\n",
        "                10,\n",
        "                kernel_divergence_fn=kl_divergence_function,\n",
        "                activation=tf.nn.softmax,\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "        experimental_run_tf_function=False,\n",
        "    )\n",
        "\n",
        "    model.build(input_shape=[None, 32, 32, 3])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7UvxBUmtPT-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BBB network"
      ],
      "metadata": {
        "id": "HARuWExAQ6Rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bbb_model = build_and_compile_model_bbb()\n",
        "bbb_model.fit(train_images, train_labels, epochs=15)"
      ],
      "metadata": {
        "id": "mCPH-mbqST9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test images"
      ],
      "metadata": {
        "id": "bx0ZWJbUmeaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_SUBSET = 1000\n",
        "test_images_subset = test_images[:NUM_SUBSET]\n",
        "test_labels_subset = test_labels[:NUM_SUBSET]"
      ],
      "metadata": {
        "id": "J06s2J27mc7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply dataset shift"
      ],
      "metadata": {
        "id": "F8h1iHDv2IHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corruption_functions = [\n",
        "    icl.GaussianNoise,\n",
        "    icl.ShotNoise,\n",
        "    icl.ImpulseNoise,\n",
        "    icl.DefocusBlur,\n",
        "    icl.GlassBlur,\n",
        "    icl.MotionBlur,\n",
        "    icl.ZoomBlur,\n",
        "    icl.Snow,\n",
        "    icl.Frost,\n",
        "    icl.Fog,\n",
        "    icl.Brightness,\n",
        "    icl.Contrast,\n",
        "    icl.ElasticTransform,\n",
        "    icl.Pixelate,\n",
        "    icl.JpegCompression,\n",
        "]\n",
        "NUM_TYPES = len(corruption_functions)\n",
        "NUM_LEVELS = 5"
      ],
      "metadata": {
        "id": "SwLOeCcz4j4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrupted_images = []\n",
        "# loop over different corruption severities\n",
        "for corruption_severity in range(1, NUM_LEVELS+1):\n",
        "    corruption_type_batch = []\n",
        "    # loop over different corruption types\n",
        "    for corruption_type in corruption_functions:\n",
        "        corrupted_image_batch = corruption_type(\n",
        "            severity=corruption_severity, seed=0\n",
        "        )(images=test_images_subset)\n",
        "        corruption_type_batch.append(corrupted_image_batch)\n",
        "    corruption_type_batch = np.stack(corruption_type_batch, axis=0)\n",
        "    corrupted_images.append(corruption_type_batch)\n",
        "corrupted_images = np.stack(corrupted_images, axis=0)"
      ],
      "metadata": {
        "id": "LeCZUSqT_Hmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference - get predictions**"
      ],
      "metadata": {
        "id": "Po-rROa4-xwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrupted_images = corrupted_images.reshape((-1, 32, 32, 3))"
      ],
      "metadata": {
        "id": "J5KSgui--wWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions on original images\n",
        "vanilla_predictions = vanilla_model.predict(test_images_subset)\n",
        "# Get predictions on corrupted images\n",
        "vanilla_predictions_on_corrupted = vanilla_model.predict(corrupted_images)\n",
        "vanilla_predictions_on_corrupted = vanilla_predictions_on_corrupted.reshape(\n",
        "    (NUM_LEVELS, NUM_TYPES, NUM_SUBSET, -1)\n",
        ")"
      ],
      "metadata": {
        "id": "QX5_659VWvju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ensemble_predictions(images, num_inferences):\n",
        "    ensemble_predictions = tf.stack(\n",
        "        [\n",
        "            ensemble_model[ensemble_ind].predict(images)\n",
        "            for ensemble_ind in range(num_inferences)\n",
        "        ],\n",
        "        axis=0,\n",
        "    )\n",
        "    return np.mean(ensemble_predictions, axis=0)"
      ],
      "metadata": {
        "id": "skKq57cXr07U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions on original images\n",
        "ensemble_predictions = get_ensemble_predictions(\n",
        "    test_images_subset, NUM_ENSEMBLE_MEMBERS\n",
        ")\n",
        "# Get predictions on corrupted images\n",
        "ensemble_predictions_on_corrupted = get_ensemble_predictions(\n",
        "    corrupted_images, NUM_ENSEMBLE_MEMBERS\n",
        ")\n",
        "ensemble_predictions_on_corrupted = ensemble_predictions_on_corrupted.reshape(\n",
        "    (NUM_LEVELS, NUM_TYPES, NUM_SUBSET, -1)\n",
        ")"
      ],
      "metadata": {
        "id": "fsl1k9J2BJTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bbb_predictions(images, num_inferences):\n",
        "    bbb_predictions = tf.stack(\n",
        "        [bbb_model.predict(images) for _ in range(num_inferences)],\n",
        "        axis=0,\n",
        "    )\n",
        "    return np.mean(bbb_predictions, axis=0)"
      ],
      "metadata": {
        "id": "v9zugzn7BnOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_INFERENCES_BBB = 20\n",
        "# Get predictions on original images\n",
        "bbb_predictions = get_bbb_predictions(\n",
        "    test_images_subset, NUM_INFERENCES_BBB\n",
        ")\n",
        "# Get predictions on corrupted images\n",
        "bbb_predictions_on_corrupted = get_bbb_predictions(\n",
        "    corrupted_images, NUM_INFERENCES_BBB\n",
        ")\n",
        "bbb_predictions_on_corrupted = bbb_predictions_on_corrupted.reshape(\n",
        "    (NUM_LEVELS, NUM_TYPES, NUM_SUBSET, -1)\n",
        ")"
      ],
      "metadata": {
        "id": "Dt7el83xXO_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference - get classes and scores"
      ],
      "metadata": {
        "id": "4KC9CwWaXuT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classes_and_scores(model_predictions):\n",
        "    model_predicted_classes = np.argmax(model_predictions, axis=-1)\n",
        "    model_scores = np.max(model_predictions, axis=-1)\n",
        "    return model_predicted_classes, model_scores"
      ],
      "metadata": {
        "id": "Kl1eMlv6WrRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla_predicted_classes, vanilla_scores = get_classes_and_scores(\n",
        "    vanilla_predictions\n",
        ")\n",
        "(\n",
        "    vanilla_predicted_classes_on_corrupted,\n",
        "    vanilla_scores_on_corrupted,\n",
        ") = get_classes_and_scores(vanilla_predictions_on_corrupted)\n"
      ],
      "metadata": {
        "id": "ikBlVOKoFlN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    ensemble_predicted_classes,\n",
        "    ensemble_scores,\n",
        ") = get_classes_and_scores(ensemble_predictions)\n",
        "(\n",
        "    ensemble_predicted_classes_on_corrupted,\n",
        "    ensemble_scores_on_corrupted,\n",
        ") = get_classes_and_scores(ensemble_predictions_on_corrupted)\n"
      ],
      "metadata": {
        "id": "u7FkdwvfHG4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    bbb_predicted_classes,\n",
        "    bbb_scores,\n",
        ") = get_classes_and_scores(bbb_predictions)\n",
        "(\n",
        "    bbb_predicted_classes_on_corrupted,\n",
        "    bbb_scores_on_corrupted,\n",
        ") = get_classes_and_scores(bbb_predictions_on_corrupted)"
      ],
      "metadata": {
        "id": "taYH4lZBoi9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise scores over data set shift"
      ],
      "metadata": {
        "id": "WaInhfrAcg6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images = corrupted_images.reshape(\n",
        "    (NUM_LEVELS, NUM_TYPES, NUM_SUBSET, 32, 32, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "RG8I9KlHeDgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index of the selected images\n",
        "ind_image = 9\n",
        "# Define figure\n",
        "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(16, 10))\n",
        "# Loop over corruption levels\n",
        "for ind_level in range(NUM_LEVELS):\n",
        "    # Loop over corruption types\n",
        "    for ind_type in range(3):\n",
        "        # Plot slightly upscaled image for easier inspection\n",
        "        image = plot_images[ind_level, ind_type, ind_image, ...]\n",
        "        image_upscaled = cv2.resize(\n",
        "            image, dsize=(150, 150), interpolation=cv2.INTER_CUBIC\n",
        "        )\n",
        "        axes[ind_type, ind_level].imshow(image_upscaled)\n",
        "        # Get score and class predicted by vanilla model\n",
        "        vanilla_score = vanilla_scores_on_corrupted[\n",
        "            ind_level, ind_type, ind_image, ...\n",
        "        ]\n",
        "        vanilla_prediction = vanilla_predicted_classes_on_corrupted[\n",
        "            ind_level, ind_type, ind_image, ...\n",
        "        ]\n",
        "        # Get score and class predicted by ensemble model\n",
        "        ensemble_score = ensemble_scores_on_corrupted[\n",
        "            ind_level, ind_type, ind_image, ...\n",
        "        ]\n",
        "        ensemble_prediction = ensemble_predicted_classes_on_corrupted[\n",
        "            ind_level, ind_type, ind_image, ...\n",
        "        ]\n",
        "        # Get score and class predicted by BBB model\n",
        "        bbb_score = bbb_scores_on_corrupted[ind_level, ind_type, ind_image, ...]\n",
        "        bbb_prediction = bbb_predicted_classes_on_corrupted[\n",
        "            ind_level, ind_type, ind_image, ...\n",
        "        ]\n",
        "        # Plot prediction info in title\n",
        "        title_text = (\n",
        "            f\"Vanilla: {vanilla_score:.3f} \"\n",
        "            + f\"[{CLASS_NAMES[vanilla_prediction]}] \\n\"\n",
        "            + f\"Ensemble: {ensemble_score:.3f} \"\n",
        "            + f\"[{CLASS_NAMES[ensemble_prediction]}] \\n\"\n",
        "            + f\"BBB: {bbb_score:.3f} \"\n",
        "            + f\"[{CLASS_NAMES[bbb_prediction]}]\"\n",
        "        )\n",
        "        axes[ind_type, ind_level].set_title(title_text, fontsize=14)\n",
        "        # Remove axes ticks and labels\n",
        "        axes[ind_type, ind_level].axis(\"off\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p1x_CPl2clXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy"
      ],
      "metadata": {
        "id": "9MAVsgB0hO-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vanilla_acc = accuracy_score(\n",
        "    test_labels_subset.flatten(), vanilla_predicted_classes\n",
        ")\n",
        "ensemble_acc = accuracy_score(\n",
        "    test_labels_subset.flatten(), ensemble_predicted_classes\n",
        ")\n",
        "bbb_acc = accuracy_score(\n",
        "    test_labels_subset.flatten(), bbb_predicted_classes\n",
        ")"
      ],
      "metadata": {
        "id": "tfVrej51mi00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vanilla_acc)\n",
        "print(ensemble_acc)\n",
        "print(bbb_acc)"
      ],
      "metadata": {
        "id": "JGJp2tC1I-Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = [\n",
        "    {\"model_name\": \"vanilla\", \"type\": 0, \"level\": 0, \"accuracy\": vanilla_acc},\n",
        "    {\"model_name\": \"ensemble\", \"type\": 0, \"level\": 0, \"accuracy\": ensemble_acc},\n",
        "    {\"model_name\": \"bbb\", \"type\": 0, \"level\": 0, \"accuracy\": bbb_acc},\n",
        "]"
      ],
      "metadata": {
        "id": "Raczrgs0QMyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ind_type in range(NUM_TYPES):\n",
        "    for ind_level in range(NUM_LEVELS):\n",
        "        # Calculate accuracy for vanilla model\n",
        "        vanilla_acc_on_corrupted = accuracy_score(\n",
        "            test_labels_subset.flatten(),\n",
        "            vanilla_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
        "        )\n",
        "        accuracies.append(\n",
        "            {\n",
        "                \"model_name\": \"vanilla\",\n",
        "                \"type\": ind_type + 1,\n",
        "                \"level\": ind_level + 1,\n",
        "                \"accuracy\": vanilla_acc_on_corrupted,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Calculate accuracy for ensemble model\n",
        "        ensemble_acc_on_corrupted = accuracy_score(\n",
        "            test_labels_subset.flatten(),\n",
        "            ensemble_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
        "        )\n",
        "        accuracies.append(\n",
        "            {\n",
        "                \"model_name\": \"ensemble\",\n",
        "                \"type\": ind_type + 1,\n",
        "                \"level\": ind_level + 1,\n",
        "                \"accuracy\": ensemble_acc_on_corrupted,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Calculate accuracy for BBB model\n",
        "        bbb_acc_on_corrupted = accuracy_score(\n",
        "            test_labels_subset.flatten(),\n",
        "            bbb_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
        "        )\n",
        "        accuracies.append(\n",
        "            {\n",
        "                \"model_name\": \"bbb\",\n",
        "                \"type\": ind_type + 1,\n",
        "                \"level\": ind_level + 1,\n",
        "                \"accuracy\": bbb_acc_on_corrupted,\n",
        "            }\n",
        "        )"
      ],
      "metadata": {
        "id": "0R0T52Y6RFzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(accuracies)\n",
        "plt.figure(dpi=100)\n",
        "sns.boxplot(data=df, x=\"level\", y=\"accuracy\", hue=\"model_name\")\n",
        "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
        "plt.tight_layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-NpEY_-wQ4TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calibration"
      ],
      "metadata": {
        "id": "ZdpdGqG1qpkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expected_calibration_error(\n",
        "    pred_correct,\n",
        "    pred_score,\n",
        "    n_bins=5,\n",
        "):\n",
        "    \"\"\"Compute expected calibration error.\n",
        "    ----------\n",
        "    pred_correct : np.ndarray (n_samples,)\n",
        "        Whether the prediction is correct or not\n",
        "    pred_score : np.ndarray (n_samples,)\n",
        "        Confidence in the prediction\n",
        "    n_bins : int, default=5\n",
        "        Number of bins to discretize the [0, 1] interval.\n",
        "    \"\"\"\n",
        "    # Convert from bool to integer (makes counting easier)\n",
        "    pred_correct = pred_correct.astype(np.int32)\n",
        "\n",
        "    # Create bins and assign prediction scores to bins\n",
        "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
        "    binids = np.searchsorted(bins[1:-1], pred_score)\n",
        "\n",
        "    # Count number of samples and correct predictions per bin\n",
        "    bin_true_counts = np.bincount(\n",
        "        binids, weights=pred_correct, minlength=len(bins)\n",
        "    )\n",
        "    bin_counts = np.bincount(binids, minlength=len(bins))\n",
        "\n",
        "    # Calculate sum of confidence scores per bin\n",
        "    bin_probs = np.bincount(binids, weights=pred_score, minlength=len(bins))\n",
        "\n",
        "    # Identify bins that contain samples\n",
        "    nonzero = bin_counts != 0\n",
        "    # Calculate accuracy for every bin\n",
        "    bin_acc = bin_true_counts[nonzero] / bin_counts[nonzero]\n",
        "    # Calculate average confidence scores per bin\n",
        "    bin_conf = bin_probs[nonzero] / bin_counts[nonzero]\n",
        "\n",
        "    # bin_counts_nonzero = bin_counts[nonzero]\n",
        "    # array_diff = bin_acc - bin_conf\n",
        "    # positive = array_diff > 0.0\n",
        "    # return np.average(array_diff[positive], weights=bin_counts_nonzero[positive])\n",
        "\n",
        "    return np.average(np.abs(bin_acc - bin_conf), weights=bin_counts[nonzero])"
      ],
      "metadata": {
        "id": "gMSXekrg-4A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_BINS = 10\n",
        "\n",
        "vanilla_cal = expected_calibration_error(\n",
        "    test_labels_subset.flatten() == vanilla_predicted_classes,\n",
        "    vanilla_scores,\n",
        "    n_bins=NUM_BINS,\n",
        ")\n",
        "\n",
        "ensemble_cal = expected_calibration_error(\n",
        "    test_labels_subset.flatten() == ensemble_predicted_classes,\n",
        "    ensemble_scores,\n",
        "    n_bins=NUM_BINS,\n",
        ")\n",
        "\n",
        "bbb_cal = expected_calibration_error(\n",
        "    test_labels_subset.flatten() == bbb_predicted_classes,\n",
        "    bbb_scores,\n",
        "    n_bins=NUM_BINS,\n",
        ")"
      ],
      "metadata": {
        "id": "xwRIMgWPqpQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vanilla_cal)\n",
        "print(ensemble_cal)\n",
        "print(bbb_cal)\n",
        "\n"
      ],
      "metadata": {
        "id": "0XWm-p5DWYCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration = [\n",
        "    {\n",
        "        \"model_name\": \"vanilla\",\n",
        "        \"type\": 0,\n",
        "        \"level\": 0,\n",
        "        \"calibration_error\": vanilla_cal,\n",
        "    },\n",
        "    {\n",
        "        \"model_name\": \"ensemble\",\n",
        "        \"type\": 0,\n",
        "        \"level\": 0,\n",
        "        \"calibration_error\": ensemble_cal,\n",
        "    },\n",
        "    {\n",
        "        \"model_name\": \"bbb\",\n",
        "        \"type\": 0,\n",
        "        \"level\": 0,\n",
        "        \"calibration_error\": bbb_cal,\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "vuDFiNP3RMA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ind_type in range(NUM_TYPES):\n",
        "    for ind_level in range(NUM_LEVELS):\n",
        "        # Calculate calibration error for vanilla model\n",
        "        vanilla_cal_on_corrupted = expected_calibration_error(\n",
        "            test_labels_subset.flatten()\n",
        "            == vanilla_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
        "            vanilla_scores_on_corrupted[ind_level, ind_type, :],\n",
        "        )\n",
        "        calibration.append(\n",
        "            {\n",
        "                \"model_name\": \"vanilla\",\n",
        "                \"type\": ind_type + 1,\n",
        "                \"level\": ind_level + 1,\n",
        "                \"calibration_error\": vanilla_cal_on_corrupted,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Calculate calibration error for ensemble model\n",
        "        ensemble_cal_on_corrupted = expected_calibration_error(\n",
        "            test_labels_subset.flatten()\n",
        "            == ensemble_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
        "            ensemble_scores_on_corrupted[ind_level, ind_type, :],\n",
        "        )\n",
        "        calibration.append(\n",
        "            {\n",
        "                \"model_name\": \"ensemble\",\n",
        "                \"type\": ind_type + 1,\n",
        "                \"level\": ind_level + 1,\n",
        "                \"calibration_error\": ensemble_cal_on_corrupted,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Calculate calibration error for BBB model\n",
        "        bbb_cal_on_corrupted = expected_calibration_error(\n",
        "            test_labels_subset.flatten()\n",
        "            == bbb_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
        "            bbb_scores_on_corrupted[ind_level, ind_type, :],\n",
        "        )\n",
        "        calibration.append(\n",
        "            {\n",
        "                \"model_name\": \"bbb\",\n",
        "                \"type\": ind_type + 1,\n",
        "                \"level\": ind_level + 1,\n",
        "                \"calibration_error\": bbb_cal_on_corrupted,\n",
        "            }\n",
        "        )"
      ],
      "metadata": {
        "id": "TT3T1Wx2X3Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(calibration)\n",
        "plt.figure(dpi=100)\n",
        "sns.boxplot(data=df, x=\"level\", y=\"calibration_error\", hue=\"model_name\")\n",
        "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
        "plt.tight_layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e6mS3eKhYkOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}