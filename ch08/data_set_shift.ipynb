{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFR87567AdMy"
   },
   "outputs": [],
   "source": [
    "!pip install imagecorruptions\n",
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seigaQeUBshi"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade imgaug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfpy9RWl5Nkj"
   },
   "source": [
    "Walk through the code example, using a vanilla neural network, A network trained with Bayes By Backprop and a deep ensemble.\n",
    "Use Cifar 10 data set and plot accuracy and calibration histograms over severity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPllJCh-u5i1"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imgaug.augmenters.imgcorruptlike as icl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOzqKz8VQXWL"
   },
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQeQN5_S_ykm"
   },
   "outputs": [],
   "source": [
    "cifar = tf.keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJAxqam5GtAC"
   },
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuGZ_dG0QwJD"
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN_EXAMPLES = train_images.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcYKRDJfQbqw"
   },
   "source": [
    "Define helper functions to define vanilla and ensemble networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFgbgMPlAko6"
   },
   "outputs": [],
   "source": [
    "def cnn_building_block(num_filters):\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(filters=num_filters, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPool2D(strides=2),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def build_and_compile_model():\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Rescaling(1.0 / 255, input_shape=(32, 32, 3)),\n",
    "            cnn_building_block(16),\n",
    "            cnn_building_block(32),\n",
    "            cnn_building_block(64),\n",
    "            tf.keras.layers.MaxPool2D(strides=2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM2h951cQe97"
   },
   "source": [
    "Vanilla models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwu7d9aBBK6B"
   },
   "outputs": [],
   "source": [
    "vanilla_model = build_and_compile_model()\n",
    "vanilla_model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLtiGfWWQoE0"
   },
   "source": [
    "Deep ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0LmARTBLsGh"
   },
   "outputs": [],
   "source": [
    "NUM_ENSEMBLE_MEMBERS = 5\n",
    "ensemble_model = []\n",
    "for ind in range(NUM_ENSEMBLE_MEMBERS):\n",
    "    member = build_and_compile_model()\n",
    "    print(f\"Train model {ind:02}\")\n",
    "    member.fit(train_images, train_labels, epochs=10)\n",
    "    ensemble_model.append(member)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrS4KhaPQtlE"
   },
   "source": [
    "Define helper functions to BBB network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UvxBUmtPT-m"
   },
   "outputs": [],
   "source": [
    "def cnn_building_block_bbb(num_filters, kl_divergence_function):\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.Convolution2DReparameterization(\n",
    "                num_filters,\n",
    "                kernel_size=(3, 3),\n",
    "                kernel_divergence_fn=kl_divergence_function,\n",
    "                activation=tf.nn.relu,\n",
    "            ),\n",
    "            tf.keras.layers.MaxPool2D(strides=2),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def build_and_compile_model_bbb():\n",
    "    kl_divergence_function = lambda q, p, _: tfp.distributions.kl_divergence(q, p) / tf.cast(\n",
    "        NUM_TRAIN_EXAMPLES, dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Rescaling(1.0 / 255, input_shape=(32, 32, 3)),\n",
    "            cnn_building_block_bbb(16, kl_divergence_function),\n",
    "            cnn_building_block_bbb(32, kl_divergence_function),\n",
    "            cnn_building_block_bbb(64, kl_divergence_function),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tfp.layers.DenseReparameterization(\n",
    "                64,\n",
    "                kernel_divergence_fn=kl_divergence_function,\n",
    "                activation=tf.nn.relu,\n",
    "            ),\n",
    "            tfp.layers.DenseReparameterization(\n",
    "                10,\n",
    "                kernel_divergence_fn=kl_divergence_function,\n",
    "                activation=tf.nn.softmax,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "        experimental_run_tf_function=False,\n",
    "    )\n",
    "\n",
    "    model.build(input_shape=[None, 32, 32, 3])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HARuWExAQ6Rv"
   },
   "source": [
    "BBB network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCPH-mbqST9j"
   },
   "outputs": [],
   "source": [
    "bbb_model = build_and_compile_model_bbb()\n",
    "bbb_model.fit(train_images, train_labels, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx0ZWJbUmeaj"
   },
   "source": [
    "Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J06s2J27mc7K"
   },
   "outputs": [],
   "source": [
    "NUM_SUBSET = 1000\n",
    "test_images_subset = test_images[:NUM_SUBSET]\n",
    "test_labels_subset = test_labels[:NUM_SUBSET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8h1iHDv2IHb"
   },
   "source": [
    "Apply dataset shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwLOeCcz4j4U"
   },
   "outputs": [],
   "source": [
    "corruption_functions = [\n",
    "    icl.GaussianNoise,\n",
    "    icl.ShotNoise,\n",
    "    icl.ImpulseNoise,\n",
    "    icl.DefocusBlur,\n",
    "    icl.GlassBlur,\n",
    "    icl.MotionBlur,\n",
    "    icl.ZoomBlur,\n",
    "    icl.Snow,\n",
    "    icl.Frost,\n",
    "    icl.Fog,\n",
    "    icl.Brightness,\n",
    "    icl.Contrast,\n",
    "    icl.ElasticTransform,\n",
    "    icl.Pixelate,\n",
    "    icl.JpegCompression,\n",
    "]\n",
    "NUM_TYPES = len(corruption_functions)\n",
    "NUM_LEVELS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeCZUSqT_Hmg"
   },
   "outputs": [],
   "source": [
    "corrupted_images = []\n",
    "# loop over different corruption severities\n",
    "for corruption_severity in range(1, NUM_LEVELS + 1):\n",
    "    corruption_type_batch = []\n",
    "    # loop over different corruption types\n",
    "    for corruption_type in corruption_functions:\n",
    "        corrupted_image_batch = corruption_type(severity=corruption_severity, seed=0)(\n",
    "            images=test_images_subset\n",
    "        )\n",
    "        corruption_type_batch.append(corrupted_image_batch)\n",
    "    corruption_type_batch = np.stack(corruption_type_batch, axis=0)\n",
    "    corrupted_images.append(corruption_type_batch)\n",
    "corrupted_images = np.stack(corrupted_images, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po-rROa4-xwd"
   },
   "source": [
    "**Inference - get predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5KSgui--wWr"
   },
   "outputs": [],
   "source": [
    "corrupted_images = corrupted_images.reshape((-1, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QX5_659VWvju"
   },
   "outputs": [],
   "source": [
    "# Get predictions on original images\n",
    "vanilla_predictions = vanilla_model.predict(test_images_subset)\n",
    "# Get predictions on corrupted images\n",
    "vanilla_predictions_on_corrupted = vanilla_model.predict(corrupted_images)\n",
    "vanilla_predictions_on_corrupted = vanilla_predictions_on_corrupted.reshape(\n",
    "    (NUM_LEVELS, NUM_TYPES, NUM_SUBSET, -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skKq57cXr07U"
   },
   "outputs": [],
   "source": [
    "def get_ensemble_predictions(images, num_inferences):\n",
    "    ensemble_predictions = tf.stack(\n",
    "        [ensemble_model[ensemble_ind].predict(images) for ensemble_ind in range(num_inferences)],\n",
    "        axis=0,\n",
    "    )\n",
    "    return np.mean(ensemble_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsl1k9J2BJTV"
   },
   "outputs": [],
   "source": [
    "# Get predictions on original images\n",
    "ensemble_predictions = get_ensemble_predictions(test_images_subset, NUM_ENSEMBLE_MEMBERS)\n",
    "# Get predictions on corrupted images\n",
    "ensemble_predictions_on_corrupted = get_ensemble_predictions(corrupted_images, NUM_ENSEMBLE_MEMBERS)\n",
    "ensemble_predictions_on_corrupted = ensemble_predictions_on_corrupted.reshape(\n",
    "    (NUM_LEVELS, NUM_TYPES, NUM_SUBSET, -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9zugzn7BnOI"
   },
   "outputs": [],
   "source": [
    "def get_bbb_predictions(images, num_inferences):\n",
    "    bbb_predictions = tf.stack(\n",
    "        [bbb_model.predict(images) for _ in range(num_inferences)],\n",
    "        axis=0,\n",
    "    )\n",
    "    return np.mean(bbb_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dt7el83xXO_W"
   },
   "outputs": [],
   "source": [
    "NUM_INFERENCES_BBB = 20\n",
    "# Get predictions on original images\n",
    "bbb_predictions = get_bbb_predictions(test_images_subset, NUM_INFERENCES_BBB)\n",
    "# Get predictions on corrupted images\n",
    "bbb_predictions_on_corrupted = get_bbb_predictions(corrupted_images, NUM_INFERENCES_BBB)\n",
    "bbb_predictions_on_corrupted = bbb_predictions_on_corrupted.reshape(\n",
    "    (NUM_LEVELS, NUM_TYPES, NUM_SUBSET, -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KC9CwWaXuT_"
   },
   "source": [
    "Inference - get classes and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kl1eMlv6WrRU"
   },
   "outputs": [],
   "source": [
    "def get_classes_and_scores(model_predictions):\n",
    "    model_predicted_classes = np.argmax(model_predictions, axis=-1)\n",
    "    model_scores = np.max(model_predictions, axis=-1)\n",
    "    return model_predicted_classes, model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikBlVOKoFlN4"
   },
   "outputs": [],
   "source": [
    "vanilla_predicted_classes, vanilla_scores = get_classes_and_scores(vanilla_predictions)\n",
    "(\n",
    "    vanilla_predicted_classes_on_corrupted,\n",
    "    vanilla_scores_on_corrupted,\n",
    ") = get_classes_and_scores(vanilla_predictions_on_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7FkdwvfHG4y"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    ensemble_predicted_classes,\n",
    "    ensemble_scores,\n",
    ") = get_classes_and_scores(ensemble_predictions)\n",
    "(\n",
    "    ensemble_predicted_classes_on_corrupted,\n",
    "    ensemble_scores_on_corrupted,\n",
    ") = get_classes_and_scores(ensemble_predictions_on_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taYH4lZBoi9a"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    bbb_predicted_classes,\n",
    "    bbb_scores,\n",
    ") = get_classes_and_scores(bbb_predictions)\n",
    "(\n",
    "    bbb_predicted_classes_on_corrupted,\n",
    "    bbb_scores_on_corrupted,\n",
    ") = get_classes_and_scores(bbb_predictions_on_corrupted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaInhfrAcg6Y"
   },
   "source": [
    "Visualise scores over data set shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RG8I9KlHeDgI"
   },
   "outputs": [],
   "source": [
    "plot_images = corrupted_images.reshape((NUM_LEVELS, NUM_TYPES, NUM_SUBSET, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1x_CPl2clXW"
   },
   "outputs": [],
   "source": [
    "# Index of the selected images\n",
    "ind_image = 9\n",
    "# Define figure\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(16, 10))\n",
    "# Loop over corruption levels\n",
    "for ind_level in range(NUM_LEVELS):\n",
    "    # Loop over corruption types\n",
    "    for ind_type in range(3):\n",
    "        # Plot slightly upscaled image for easier inspection\n",
    "        image = plot_images[ind_level, ind_type, ind_image, ...]\n",
    "        image_upscaled = cv2.resize(image, dsize=(150, 150), interpolation=cv2.INTER_CUBIC)\n",
    "        axes[ind_type, ind_level].imshow(image_upscaled)\n",
    "        # Get score and class predicted by vanilla model\n",
    "        vanilla_score = vanilla_scores_on_corrupted[ind_level, ind_type, ind_image, ...]\n",
    "        vanilla_prediction = vanilla_predicted_classes_on_corrupted[\n",
    "            ind_level, ind_type, ind_image, ...\n",
    "        ]\n",
    "        # Get score and class predicted by ensemble model\n",
    "        ensemble_score = ensemble_scores_on_corrupted[ind_level, ind_type, ind_image, ...]\n",
    "        ensemble_prediction = ensemble_predicted_classes_on_corrupted[\n",
    "            ind_level, ind_type, ind_image, ...\n",
    "        ]\n",
    "        # Get score and class predicted by BBB model\n",
    "        bbb_score = bbb_scores_on_corrupted[ind_level, ind_type, ind_image, ...]\n",
    "        bbb_prediction = bbb_predicted_classes_on_corrupted[ind_level, ind_type, ind_image, ...]\n",
    "        # Plot prediction info in title\n",
    "        title_text = (\n",
    "            f\"Vanilla: {vanilla_score:.3f} \"\n",
    "            + f\"[{CLASS_NAMES[vanilla_prediction]}] \\n\"\n",
    "            + f\"Ensemble: {ensemble_score:.3f} \"\n",
    "            + f\"[{CLASS_NAMES[ensemble_prediction]}] \\n\"\n",
    "            + f\"BBB: {bbb_score:.3f} \"\n",
    "            + f\"[{CLASS_NAMES[bbb_prediction]}]\"\n",
    "        )\n",
    "        axes[ind_type, ind_level].set_title(title_text, fontsize=14)\n",
    "        # Remove axes ticks and labels\n",
    "        axes[ind_type, ind_level].axis(\"off\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MAVsgB0hO-t"
   },
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfVrej51mi00"
   },
   "outputs": [],
   "source": [
    "vanilla_acc = accuracy_score(test_labels_subset.flatten(), vanilla_predicted_classes)\n",
    "ensemble_acc = accuracy_score(test_labels_subset.flatten(), ensemble_predicted_classes)\n",
    "bbb_acc = accuracy_score(test_labels_subset.flatten(), bbb_predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGJp2tC1I-Fp"
   },
   "outputs": [],
   "source": [
    "print(vanilla_acc)\n",
    "print(ensemble_acc)\n",
    "print(bbb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Raczrgs0QMyk"
   },
   "outputs": [],
   "source": [
    "accuracies = [\n",
    "    {\"model_name\": \"vanilla\", \"type\": 0, \"level\": 0, \"accuracy\": vanilla_acc},\n",
    "    {\"model_name\": \"ensemble\", \"type\": 0, \"level\": 0, \"accuracy\": ensemble_acc},\n",
    "    {\"model_name\": \"bbb\", \"type\": 0, \"level\": 0, \"accuracy\": bbb_acc},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0R0T52Y6RFzU"
   },
   "outputs": [],
   "source": [
    "for ind_type in range(NUM_TYPES):\n",
    "    for ind_level in range(NUM_LEVELS):\n",
    "        # Calculate accuracy for vanilla model\n",
    "        vanilla_acc_on_corrupted = accuracy_score(\n",
    "            test_labels_subset.flatten(),\n",
    "            vanilla_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
    "        )\n",
    "        accuracies.append(\n",
    "            {\n",
    "                \"model_name\": \"vanilla\",\n",
    "                \"type\": ind_type + 1,\n",
    "                \"level\": ind_level + 1,\n",
    "                \"accuracy\": vanilla_acc_on_corrupted,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Calculate accuracy for ensemble model\n",
    "        ensemble_acc_on_corrupted = accuracy_score(\n",
    "            test_labels_subset.flatten(),\n",
    "            ensemble_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
    "        )\n",
    "        accuracies.append(\n",
    "            {\n",
    "                \"model_name\": \"ensemble\",\n",
    "                \"type\": ind_type + 1,\n",
    "                \"level\": ind_level + 1,\n",
    "                \"accuracy\": ensemble_acc_on_corrupted,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Calculate accuracy for BBB model\n",
    "        bbb_acc_on_corrupted = accuracy_score(\n",
    "            test_labels_subset.flatten(),\n",
    "            bbb_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
    "        )\n",
    "        accuracies.append(\n",
    "            {\n",
    "                \"model_name\": \"bbb\",\n",
    "                \"type\": ind_type + 1,\n",
    "                \"level\": ind_level + 1,\n",
    "                \"accuracy\": bbb_acc_on_corrupted,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NpEY_-wQ4TM"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(accuracies)\n",
    "plt.figure(dpi=100)\n",
    "sns.boxplot(data=df, x=\"level\", y=\"accuracy\", hue=\"model_name\")\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdpdGqG1qpkW"
   },
   "source": [
    "Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMSXekrg-4A2"
   },
   "outputs": [],
   "source": [
    "def expected_calibration_error(\n",
    "    pred_correct,\n",
    "    pred_score,\n",
    "    n_bins=5,\n",
    "):\n",
    "    \"\"\"Compute expected calibration error.\n",
    "    ----------\n",
    "    pred_correct : np.ndarray (n_samples,)\n",
    "        Whether the prediction is correct or not\n",
    "    pred_score : np.ndarray (n_samples,)\n",
    "        Confidence in the prediction\n",
    "    n_bins : int, default=5\n",
    "        Number of bins to discretize the [0, 1] interval.\n",
    "    \"\"\"\n",
    "    # Convert from bool to integer (makes counting easier)\n",
    "    pred_correct = pred_correct.astype(np.int32)\n",
    "\n",
    "    # Create bins and assign prediction scores to bins\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    binids = np.searchsorted(bins[1:-1], pred_score)\n",
    "\n",
    "    # Count number of samples and correct predictions per bin\n",
    "    bin_true_counts = np.bincount(binids, weights=pred_correct, minlength=len(bins))\n",
    "    bin_counts = np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    # Calculate sum of confidence scores per bin\n",
    "    bin_probs = np.bincount(binids, weights=pred_score, minlength=len(bins))\n",
    "\n",
    "    # Identify bins that contain samples\n",
    "    nonzero = bin_counts != 0\n",
    "    # Calculate accuracy for every bin\n",
    "    bin_acc = bin_true_counts[nonzero] / bin_counts[nonzero]\n",
    "    # Calculate average confidence scores per bin\n",
    "    bin_conf = bin_probs[nonzero] / bin_counts[nonzero]\n",
    "\n",
    "    # bin_counts_nonzero = bin_counts[nonzero]\n",
    "    # array_diff = bin_acc - bin_conf\n",
    "    # positive = array_diff > 0.0\n",
    "    # return np.average(array_diff[positive], weights=bin_counts_nonzero[positive])\n",
    "\n",
    "    return np.average(np.abs(bin_acc - bin_conf), weights=bin_counts[nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwRIMgWPqpQ4"
   },
   "outputs": [],
   "source": [
    "NUM_BINS = 10\n",
    "\n",
    "vanilla_cal = expected_calibration_error(\n",
    "    test_labels_subset.flatten() == vanilla_predicted_classes,\n",
    "    vanilla_scores,\n",
    "    n_bins=NUM_BINS,\n",
    ")\n",
    "\n",
    "ensemble_cal = expected_calibration_error(\n",
    "    test_labels_subset.flatten() == ensemble_predicted_classes,\n",
    "    ensemble_scores,\n",
    "    n_bins=NUM_BINS,\n",
    ")\n",
    "\n",
    "bbb_cal = expected_calibration_error(\n",
    "    test_labels_subset.flatten() == bbb_predicted_classes,\n",
    "    bbb_scores,\n",
    "    n_bins=NUM_BINS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XWm-p5DWYCm"
   },
   "outputs": [],
   "source": [
    "print(vanilla_cal)\n",
    "print(ensemble_cal)\n",
    "print(bbb_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuDFiNP3RMA2"
   },
   "outputs": [],
   "source": [
    "calibration = [\n",
    "    {\n",
    "        \"model_name\": \"vanilla\",\n",
    "        \"type\": 0,\n",
    "        \"level\": 0,\n",
    "        \"calibration_error\": vanilla_cal,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"ensemble\",\n",
    "        \"type\": 0,\n",
    "        \"level\": 0,\n",
    "        \"calibration_error\": ensemble_cal,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"bbb\",\n",
    "        \"type\": 0,\n",
    "        \"level\": 0,\n",
    "        \"calibration_error\": bbb_cal,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TT3T1Wx2X3Vf"
   },
   "outputs": [],
   "source": [
    "for ind_type in range(NUM_TYPES):\n",
    "    for ind_level in range(NUM_LEVELS):\n",
    "        # Calculate calibration error for vanilla model\n",
    "        vanilla_cal_on_corrupted = expected_calibration_error(\n",
    "            test_labels_subset.flatten()\n",
    "            == vanilla_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
    "            vanilla_scores_on_corrupted[ind_level, ind_type, :],\n",
    "        )\n",
    "        calibration.append(\n",
    "            {\n",
    "                \"model_name\": \"vanilla\",\n",
    "                \"type\": ind_type + 1,\n",
    "                \"level\": ind_level + 1,\n",
    "                \"calibration_error\": vanilla_cal_on_corrupted,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Calculate calibration error for ensemble model\n",
    "        ensemble_cal_on_corrupted = expected_calibration_error(\n",
    "            test_labels_subset.flatten()\n",
    "            == ensemble_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
    "            ensemble_scores_on_corrupted[ind_level, ind_type, :],\n",
    "        )\n",
    "        calibration.append(\n",
    "            {\n",
    "                \"model_name\": \"ensemble\",\n",
    "                \"type\": ind_type + 1,\n",
    "                \"level\": ind_level + 1,\n",
    "                \"calibration_error\": ensemble_cal_on_corrupted,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Calculate calibration error for BBB model\n",
    "        bbb_cal_on_corrupted = expected_calibration_error(\n",
    "            test_labels_subset.flatten()\n",
    "            == bbb_predicted_classes_on_corrupted[ind_level, ind_type, :],\n",
    "            bbb_scores_on_corrupted[ind_level, ind_type, :],\n",
    "        )\n",
    "        calibration.append(\n",
    "            {\n",
    "                \"model_name\": \"bbb\",\n",
    "                \"type\": ind_type + 1,\n",
    "                \"level\": ind_level + 1,\n",
    "                \"calibration_error\": bbb_cal_on_corrupted,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6mS3eKhYkOt"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(calibration)\n",
    "plt.figure(dpi=100)\n",
    "sns.boxplot(data=df, x=\"level\", y=\"calibration_error\", hue=\"model_name\")\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}